{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description de MNIST \"Handwritten Digit Recognition Problem\"\n",
    "\n",
    "MNIST est un jeu de données développé par Yann LeCun, Corinna Cortes et Christopher Burges pour évaluer les modèles d’apprentissage automatique sur la classification des chiffres manuscrits.\n",
    "\n",
    "Ce jeu de données a été construit à partir de plusieurs ensembles de documents numérisés provenant du National Institute of Standards and Technology (NIST). Nommé **Modified NIST**, ou **MNIST**.\n",
    "\n",
    "Chaque image est un carré de **28×28 pixels** (soit **784 pixels** au total). Une division standard du jeu de données est utilisée pour l'évaluation et la comparaison des modèles : **60 000 images** servent à l'entraînement du modèle, et un ensemble distinct de **10 000 images** est utilisé pour le tester.\n",
    "\n",
    "Il s'agit d'une tâche de reconnaissance de chiffres. Il y a donc **dix chiffres** (de 0 à 9), soit **dix classes** à prédire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le schéma d’architecture des réseaux de neurones que nous allons réaliser dans ce workshop. \n",
    "\n",
    "<img src=\"Image1.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Charger la dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = #A COMPLETER\n",
    "\n",
    "print(f\"forme des images {x_train.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, nous devons spécifier quelques paramètres pour l'apprentissage:\n",
    "<ul>\n",
    "    <li>La longueur et la largeur des images. </li>\n",
    "    <li>La taille du batch.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h, image_w = x_train.shape[1], x_train.shape[2]\n",
    "batch_s = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data processing :Normalisation des images (mise à l'échelle entre 0 et 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construire les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_small_model(): # create small model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model\n",
    "\n",
    "def build_medium_model(): # create medium model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model\n",
    "\n",
    "def build_large_model(): # create large model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Entraîner les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"small\": build_small_model(), \"medium\": build_medium_model(), \"large\": build_large_model()}\n",
    "histories = {}\n",
    "\n",
    "SAVE_DIR = \"mnist_results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.compile(\n",
    "        #A COMPLETER\n",
    "    )\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    histories[name] = history.history\n",
    "    model.save(os.path.join(SAVE_DIR, f\"{name}_model.h5\"))\n",
    "    np.save(os.path.join(SAVE_DIR, f\"{name}_history.npy\"), history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Validation : Plot Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy & Loss for all models\n",
    "def plot_all_metrics(histories):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1,2,1)\n",
    "    for name, history in histories.items():\n",
    "        plt.plot(history['accuracy'], label=f'{name} Train Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label=f'{name} Validation Accuracy', linestyle='dashed')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1,2,2)\n",
    "    for name, history in histories.items():\n",
    "        plt.plot(history['loss'], label=f'{name} Train Loss')\n",
    "        plt.plot(history['val_loss'], label=f'{name} Validation Loss', linestyle='dashed')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Model Loss Comparison')\n",
    "    \n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"models_accuracy_loss_plot.png\"))\n",
    "    plt.show()\n",
    "\n",
    "plot_all_metrics(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    results[name] = {\"accuracy\": scores[1] * 100, \"error_rate\": 100 - scores[1] * 100}\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse comparative des optimizers pour MNIST\n",
    "\n",
    "Nous avons utilisé 'Adam' comme algorithme d’optimisation. Cependant, d’autres optimizers peuvent avoir un impact différent sur la convergence et la précision du modèle. Testez au moins trois autres optimizers parmi les suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste tous les optimizers disponibles dans TensorFlow\n",
    "optimizers = [opt for opt in dir(tf.keras.optimizers) if not opt.startswith(\"__\")]\n",
    "print(optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executer cette ligne pour voir la documentation de chaque optimizer\n",
    "help(tf.keras.optimizers.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Comparez leurs performances en traçant les courbes de perte et d’accuracy sur l’ensemble d'entraînement et de validation.\n",
    "\n",
    "2. Analysez la vitesse de convergence et la précision finale de chaque optimizer.\n",
    "\n",
    "3. Quel optimizer semble le plus efficace pour ce problème et pourquoi ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
