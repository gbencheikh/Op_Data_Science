{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description de MNIST \"Handwritten Digit Recognition Problem\"\n",
    "\n",
    "MNIST est un jeu de données développé par Yann LeCun, Corinna Cortes et Christopher Burges pour évaluer les modèles d’apprentissage automatique sur la classification des chiffres manuscrits.\n",
    "\n",
    "Ce jeu de données a été construit à partir de plusieurs ensembles de documents numérisés provenant du National Institute of Standards and Technology (NIST). Nommé **Modified NIST**, ou **MNIST**.\n",
    "\n",
    "Chaque image est un carré de **28×28 pixels** (soit **784 pixels** au total). Une division standard du jeu de données est utilisée pour l'évaluation et la comparaison des modèles : **60 000 images** servent à l'entraînement du modèle, et un ensemble distinct de **10 000 images** est utilisé pour le tester.\n",
    "\n",
    "Il s'agit d'une tâche de reconnaissance de chiffres. Il y a donc **dix chiffres** (de 0 à 9), soit **dix classes** à prédire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le schéma d’architecture des réseaux de neurones que nous allons réaliser dans ce workshop. \n",
    "\n",
    "<img src=\"Image1.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gbencheikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Charger la dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forme des images (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = #A COMPLETER\n",
    "\n",
    "print(f\"forme des images {x_train.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, nous devons spécifier quelques paramètres pour l'apprentissage:\n",
    "<ul>\n",
    "    <li>La longueur et la largeur des images. </li>\n",
    "    <li>La taille du batch.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h, image_w = x_train.shape[1], x_train.shape[2]\n",
    "batch_s = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data processing :Normalisation des images (mise à l'échelle entre 0 et 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construire le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_small_model(): # create small model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model\n",
    "\n",
    "def build_medium_model(): # create medium model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model\n",
    "\n",
    "def build_large_model(): # create large model\n",
    "    model = Sequential()\n",
    "    #A COMPLETER\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Entraîner les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"small\": build_small_model(), \"medium\": build_medium_model(), \"large\": build_large_model()}\n",
    "histories = {}\n",
    "\n",
    "SAVE_DIR = \"mnist_results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.compile(\n",
    "        #A COMPLETER\n",
    "    )\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    histories[name] = history.history\n",
    "    model.save(os.path.join(SAVE_DIR, f\"{name}_model.h5\"))\n",
    "    np.save(os.path.join(SAVE_DIR, f\"{name}_history.npy\"), history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Validation : Plot Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy & Loss for all models\n",
    "def plot_all_metrics(histories):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1,2,1)\n",
    "    for name, history in histories.items():\n",
    "        plt.plot(history['accuracy'], label=f'{name} Train Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label=f'{name} Validation Accuracy', linestyle='dashed')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1,2,2)\n",
    "    for name, history in histories.items():\n",
    "        plt.plot(history['loss'], label=f'{name} Train Loss')\n",
    "        plt.plot(history['val_loss'], label=f'{name} Validation Loss', linestyle='dashed')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Model Loss Comparison')\n",
    "    \n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"models_accuracy_loss_plot.png\"))\n",
    "    plt.show()\n",
    "\n",
    "plot_all_metrics(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    results[name] = {\"accuracy\": scores[1] * 100, \"error_rate\": 100 - scores[1] * 100}\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
