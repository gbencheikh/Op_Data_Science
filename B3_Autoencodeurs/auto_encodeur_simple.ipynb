{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencodeur\n",
    "\n",
    "Aujourd'hui, nous allons apprendre ensemble √† construire un autoencodeur simple en utilisant TensorFlow et Keras.\n",
    "Un autoencodeur est un r√©seau de neurones con√ßu pour apprendre √† compresser des donn√©es en un vecteur de petite dimension\n",
    "(appel√© repr√©sentation latente), puis √† les reconstruire. C'est un peu comme un syst√®me de compression et de d√©compression d'images.\n",
    "L'objectif est de compresser les images d'entr√©e tout en conservant un maximum d'informations utiles.\n",
    "√Ä la fin, vous serez capables de visualiser les images d'origine et les images reconstruites pour juger de la qualit√© de l'autoencodeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des donn√©es MNIST\n",
    "\n",
    "<blockquote>\n",
    "Comme nous avons vu au workshops pr√©c√©dents MNIST est une base de donn√©es contenant des chiffres manuscrits (0 √† 9) en noir et blanc.\n",
    "\n",
    "On charge les images d'entra√Ænement directement depuis Keras.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHARGER LES DONNEES DE MNIST - A COMPLETER  \n",
    "\n",
    "print(\"Donn√©es MNIST charg√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = # A COMPLETER\n",
    "print(f\"Les images sont des matrices {image_shape} avec des valeurs de 0 √† 2^8 = 255.\")\n",
    "\n",
    "image_h = # A COMPLETER\n",
    "image_w = # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scale data : Normalisation des donn√©es \n",
    "\n",
    "<blockquote>\n",
    "On normalise ces valeurs pour les rendre entre 0 et 1, ce qui aide l'entra√Ænement.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = # A COMPLETER\n",
    "test_images = # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aplatir les images (28x28 -> 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = # A COMPLETER\n",
    "test_images = # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construire le mod√®le : D√©finition de l'autoencodeur\n",
    "\n",
    "Un autoencodeur est compos√© de deux parties principales :\n",
    "* L'encodeur, qui compresse l'image en un vecteur de petite dimension.\n",
    "* Le d√©codeur, qui reconstruit l'image √† partir de ce vecteur compress√©.\n",
    "\n",
    "<img src=\"autoencodeur_architecture.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder():\n",
    "    # Encodeur\n",
    "    encoder = models.Sequential([\n",
    "        # A COMPLETER\n",
    "    ])\n",
    "\n",
    "    # D√©codeur\n",
    "    decoder = models.Sequential([\n",
    "        # A COMPLETER\n",
    "    ])\n",
    "\n",
    "    # Autoencodeur complet\n",
    "    autoencoder = models.Sequential([encoder, decoder])\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = build_autoencoder()\n",
    "\n",
    "# definir l'algorithme d'optimisation et la fonction loss \n",
    "optimizer = #A COMPLETER\n",
    "loss = #A COMPLETER \n",
    "\n",
    "autoencoder.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entra√Ænement de l'autoencodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On d√©finit ici quelques param√®tres pour l'entra√Ænement :\n",
    "- batch_size : nombre d'images trait√©es en parall√®le\n",
    "- epochs : nombre d'it√©rations sur l'ensemble des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(# A completer\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sauvegarder le mod√®le "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# üíæ Cr√©ation du dossier pour enregistrer les r√©sultats\n",
    "# On v√©rifie si le dossier existe d√©j√†, sinon on le cr√©e.\n",
    "SAVE_DIR = \"autoencodeur_results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER : sauvegarder le model dans le dossier SAVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder.evaluate(test_images, test_images, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "plot_all_metrics({\"Autoencoder_model\": history}, SAVE_DIR, \"model_loss_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruire des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = autoencoder.predict(test_images, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des r√©sultats\n",
    "\n",
    "On compare quelques images originales avec leurs reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # Nombre d'images √† afficher\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Image originale\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Image reconstruite\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstruit\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
